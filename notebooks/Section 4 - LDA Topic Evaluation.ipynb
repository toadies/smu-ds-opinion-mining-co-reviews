{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import os\n",
    "from tmtoolkit.topicmod.evaluate import metric_coherence_gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tech corpus\n",
      "Total workers: 8\n",
      "Tokenize the corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/225 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocab Size 51828\n",
      "[('work', 61850), ('good', 30138), ('wa', 17335), ('learn', 16445), ('management', 13353), ('place', 12317), ('great', 12001), ('job', 10333), ('employee', 8264), ('lot', 8210), ('environment', 7966), ('project', 7571), ('people', 7264), ('time', 7242), ('culture', 7189), ('life', 7123), ('opportunity', 6678), ('technology', 6068), ('part', 5862), ('balance', 5563), ('manager', 5515), ('place work', 5469), ('get', 5448), ('experience', 5350), ('good work', 5228), ('enjoy', 5183), ('work life', 5138), ('life balance', 4801), ('thing', 4389), ('year', 4388), ('ha', 4194), ('provide', 4187), ('many', 4104), ('like', 4060), ('one', 3966), ('benefit', 3892), ('train', 3857), ('also', 3852), ('skill', 3842), ('hard', 3771), ('work culture', 3552), ('well', 3422), ('co', 3409), ('friendly', 3385), ('support', 3357), ('fun', 3234), ('client', 3197), ('work environment', 3196), ('development', 3123), ('would', 3118)]\n",
      "Total parameter values to train 225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 225/225 [19:37:23<00:00, 313.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#project_path = os.path.join(os.path.dirname(__file__), \"..\")\n",
    "#print(project_path)\n",
    "num_cpus = mp.cpu_count()\n",
    "\n",
    "\n",
    "def tokenize(doc):\n",
    "    tokens = doc.split(\" \")\n",
    "    tokens = [word for word in tokens if len(word.strip()) > 0]\n",
    "    return tokens\n",
    "\n",
    "result = []\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"Loading tech corpus\")\n",
    "    with open( \"../data/tech_review_sent_corpus.pkl\", \"rb\") as f:\n",
    "        tech_review_corpus = pickle.load(f)\n",
    "    reviews = pd.DataFrame(tech_review_corpus).review.tolist()\n",
    "\n",
    "    print(\"Total workers:\", num_cpus)\n",
    "\n",
    "    print(\"Tokenize the corpus\")\n",
    "\n",
    "    with open(\"../data/stop_words.json\", \"r\") as f:\n",
    "        stop_words = json.load(f)\n",
    "\n",
    "    vectorizer = CountVectorizer(\n",
    "        min_df=3, max_df=.90, tokenizer=tokenize, stop_words=stop_words, ngram_range=(1, 2))\n",
    "    X = vectorizer.fit_transform(reviews)\n",
    "    print(\"Total Vocab Size\", len(vectorizer.vocabulary_))\n",
    "\n",
    "    sum_words = X.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx])\n",
    "                  for word, idx in vectorizer.vocabulary_.items()]\n",
    "    print(sorted(words_freq, key=lambda x: x[1], reverse=True)[:50])\n",
    "\n",
    "    topics_range = range(15, 6, -1)\n",
    "    alpha = list(np.arange(0.01, 1, 0.3))\n",
    "    #alpha.append(None)\n",
    "    beta = list(np.arange(0.01, 1, 0.3))\n",
    "    #beta.append(None)\n",
    "\n",
    "    parameters = []\n",
    "    for k in topics_range:\n",
    "        for a in alpha:\n",
    "            for b in beta:\n",
    "                parameters.append({\n",
    "                    \"k\": k, \"alpha\": a, \"beta\": b\n",
    "                })\n",
    "\n",
    "    print(\"Total parameter values to train\", len(parameters))\n",
    "\n",
    "    for param in tqdm(parameters):\n",
    "        lda = LatentDirichletAllocation(\n",
    "                learning_method=\"batch\",\n",
    "                random_state=100,\n",
    "                n_components=param[\"k\"],\n",
    "                doc_topic_prior=param[\"alpha\"],\n",
    "                topic_word_prior=param[\"beta\"],\n",
    "                n_jobs=-2\n",
    "            )\n",
    "        lda.fit(X)\n",
    "        score = metric_coherence_gensim(measure='u_mass', \n",
    "                        top_n=25, \n",
    "                        topic_word_distrib=lda.components_, \n",
    "                        dtm=X, \n",
    "                        vocab=np.array([x for x in vectorizer.vocabulary_.keys()]),\n",
    "                        return_mean=True)\n",
    "        result.append({\n",
    "        \"k\":param[\"k\"],\n",
    "        \"alpha\":param[\"alpha\"],\n",
    "        \"beta\":param[\"beta\"],\n",
    "        \"score\":score\n",
    "    })\n",
    "            \n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(result).to_csv(\"../data/lda_umass.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-3.448244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-3.451348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.472829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-3.476927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-3.495599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>13</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-4.360425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-4.378900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-4.417690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-4.519471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-4.521466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      k  alpha  beta     score\n",
       "200   7   0.01  0.01 -3.448244\n",
       "202   7   0.01  0.61 -3.451348\n",
       "204   7   0.01   NaN -3.472829\n",
       "203   7   0.01  0.91 -3.476927\n",
       "201   7   0.01  0.31 -3.495599\n",
       "..   ..    ...   ...       ...\n",
       "63   13   0.61  0.91 -4.360425\n",
       "12   15   0.61  0.61 -4.378900\n",
       "7    15   0.31  0.61 -4.417690\n",
       "8    15   0.31  0.91 -4.519471\n",
       "13   15   0.61  0.91 -4.521466\n",
       "\n",
       "[225 rows x 4 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values(by=['score','k'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_range = range(15, 6, -1)\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "#alpha.append(None)\n",
    "#beta = list(np.arange(0.01, 1, 0.3))\n",
    "#beta.append(None)\n",
    "\n",
    "parameters = []\n",
    "for k in topics_range:\n",
    "    for a in alpha:\n",
    "        parameters.append({\n",
    "                    \"k\": k, \"alpha\": a\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [33:03<00:00, 55.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf_result = []\n",
    "for param in tqdm(parameters):\n",
    "    nmf = NMF(n_components=param[\"k\"]\n",
    "                  ,init='nndsvd'\n",
    "                 ,random_state=100,\n",
    "                 alpha=param[\"alpha\"])\n",
    "\n",
    "    nmf.fit(X)\n",
    "    score = metric_coherence_gensim(measure='u_mass', \n",
    "                        top_n=100, \n",
    "                        topic_word_distrib=nmf.components_, \n",
    "                        dtm=X, \n",
    "                        vocab=np.array([x for x in vectorizer.vocabulary_.keys()]),\n",
    "                        return_mean=True)\n",
    "    \n",
    "    nmf_result.append({\n",
    "    \"k\":param[\"k\"],\n",
    "    \"alpha\":param[\"alpha\"],\n",
    "    \"score\":score\n",
    "    })\n",
    "            \n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(nmf_result).to_csv(\"../data/nmf_umass.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_result = pd.DataFrame(nmf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>alpha</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-3.623963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-3.623963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-3.624224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-3.626523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-3.696048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-3.698922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-3.699271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-3.722513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-3.865992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-3.865992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-3.873597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-3.875602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-3.986919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-3.986919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-3.986919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-4.002542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-4.074257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-4.075243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-4.075326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-4.075326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-4.154809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-4.164893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-4.167893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-4.171448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-4.200277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-4.209890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-4.215469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-4.215664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-4.228771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-4.232021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-4.234976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-4.236258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-4.237710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-4.238198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-4.241860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-4.263404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k  alpha     score\n",
       "32   7   0.01 -3.623963\n",
       "33   7   0.31 -3.623963\n",
       "35   7   0.91 -3.624224\n",
       "34   7   0.61 -3.626523\n",
       "29   8   0.31 -3.696048\n",
       "31   8   0.91 -3.698922\n",
       "30   8   0.61 -3.699271\n",
       "28   8   0.01 -3.722513\n",
       "24   9   0.01 -3.865992\n",
       "25   9   0.31 -3.865992\n",
       "26   9   0.61 -3.873597\n",
       "27   9   0.91 -3.875602\n",
       "21  10   0.31 -3.986919\n",
       "22  10   0.61 -3.986919\n",
       "23  10   0.91 -3.986919\n",
       "20  10   0.01 -4.002542\n",
       "16  11   0.01 -4.074257\n",
       "17  11   0.31 -4.075243\n",
       "18  11   0.61 -4.075326\n",
       "19  11   0.91 -4.075326\n",
       "8   13   0.01 -4.154809\n",
       "9   13   0.31 -4.164893\n",
       "10  13   0.61 -4.167893\n",
       "11  13   0.91 -4.171448\n",
       "12  12   0.01 -4.200277\n",
       "13  12   0.31 -4.209890\n",
       "14  12   0.61 -4.215469\n",
       "15  12   0.91 -4.215664\n",
       "4   14   0.01 -4.228771\n",
       "1   15   0.31 -4.232021\n",
       "2   15   0.61 -4.234976\n",
       "5   14   0.31 -4.236258\n",
       "3   15   0.91 -4.237710\n",
       "6   14   0.61 -4.238198\n",
       "7   14   0.91 -4.241860\n",
       "0   15   0.01 -4.263404"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_result.sort_values(by=['score','k'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from spacy.lang.en import English\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import LdaMulticore\n",
    "import multiprocessing as mp\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "# Plotting tools\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cpus = mp.cpu_count() - 1\n",
    "\n",
    "parser = English()\n",
    "\n",
    "with open(\"../Data/tech_review_sent_corpus.pkl\",\"rb\") as f:\n",
    "    tech_review_corpus = pickle.load(f)\n",
    "    \n",
    "reviews = pd.DataFrame(tech_review_corpus).review.tolist()\n",
    "\n",
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                          | 325/156988 [00:00<00:48, 3219.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total workers: 7\n",
      "Tokenize the corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 156988/156988 [00:09<00:00, 15890.33it/s]\n",
      "  4%|██▋                                                                      | 5897/156988 [00:00<00:02, 58400.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a Dictionary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 156988/156988 [00:02<00:00, 54435.28it/s]\n",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running modeling\n",
      "Total Paramters 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 300/300 [29:09:34<00:00, 349.92s/it]\n"
     ]
    }
   ],
   "source": [
    "def compute_coherence_values(param):\n",
    "    lda_model = LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=param[\"k\"], \n",
    "                                           random_state=100,\n",
    "                                           chunksize=1000,\n",
    "                                           workers = num_cpus,\n",
    "                                           passes=10,\n",
    "                                           alpha=param[\"alpha\"],\n",
    "                                           eta=param[\"beta\"],\n",
    "                                           per_word_topics=True)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=id2word, coherence='u_mass')\n",
    "    \n",
    "    param[\"coherence\"] = coherence_model_lda.get_coherence()\n",
    "\n",
    "    return param\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"Total workers:\", num_cpus)\n",
    "\n",
    "    print(\"Tokenize the corpus\")\n",
    "    #with Pool() as p:\n",
    "    processed_docs = list(tqdm(map(tokenize, reviews), total=len(reviews)))\n",
    "\n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(processed_docs)\n",
    "    # Term Document Frequency\n",
    "    print(\"Create a Dictionary\")\n",
    "    corpus = [id2word.doc2bow(text) for i, text in tqdm(enumerate(processed_docs), total=len(processed_docs))]\n",
    "\n",
    "    grid = {}\n",
    "    grid['Validation_Set'] = {}\n",
    "    # Topics range\n",
    "    min_topics = 6\n",
    "    max_topics = 15\n",
    "    step_size = 1\n",
    "    topics_range = range(max_topics, min_topics, -1)\n",
    "    # Alpha parameter\n",
    "    alpha = list(np.arange(0.01, 1, 0.3))\n",
    "    alpha.append('symmetric')\n",
    "    alpha.append('asymmetric')\n",
    "    # Beta parameter\n",
    "    beta = list(np.arange(0.01, 1, 0.3))\n",
    "    beta.append('symmetric')\n",
    "\n",
    "    parameters = []\n",
    "    for k in topics_range:\n",
    "        for a in alpha:\n",
    "            for b in beta:\n",
    "                parameters.append({\n",
    "                        \"k\":k\n",
    "                        ,\"alpha\":a\n",
    "                        ,\"beta\":b\n",
    "                        ,\"workers\":4\n",
    "                    })\n",
    "\n",
    "    print(\"Running modeling\")\n",
    "    print(\"Total Paramters\", len(parameters))\n",
    "\n",
    "    results = list(map(compute_coherence_values, tqdm(parameters)))\n",
    "    \n",
    "    gensim_umass = pd.DataFrame(results).to_csv(\"../Data/gensim_umass.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>workers</th>\n",
       "      <th>coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.61</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.325531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.31</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.334568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.353571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.359256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.61</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.384681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>13</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.702495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>12</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.882181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>14</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4</td>\n",
       "      <td>-7.272288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>13</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4</td>\n",
       "      <td>-7.395710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4</td>\n",
       "      <td>-7.927583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      k       alpha       beta  workers  coherence\n",
       "212   8        0.01       0.61        4  -2.325531\n",
       "241   7        0.01       0.31        4  -2.334568\n",
       "244   7        0.01  symmetric        4  -2.353571\n",
       "240   7        0.01       0.01        4  -2.359256\n",
       "242   7        0.01       0.61        4  -2.384681\n",
       "..   ..         ...        ...      ...        ...\n",
       "83   13   symmetric       0.91        4  -5.702495\n",
       "118  12  asymmetric       0.91        4  -5.882181\n",
       "58   14  asymmetric       0.91        4  -7.272288\n",
       "88   13  asymmetric       0.91        4  -7.395710\n",
       "28   15  asymmetric       0.91        4  -7.927583\n",
       "\n",
       "[270 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_umass.sort_values(by=['coherence'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
